{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nome: Andr√© Corr√™a Santos\r\n",
    "Nome: Henrique Damico"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "source": [
    "%matplotlib inline\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "import os\r\n",
    "import re\r\n",
    "import nltk"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "source": [
    "print('Esperamos trabalhar no diret√≥rio')\r\n",
    "print(os.getcwd())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Esperamos trabalhar no diret√≥rio\n",
      "c:\\Users\\marce\\Desktop\\Cdados\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "source": [
    "filename = 'base_de_dados.xlsx'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "source": [
    "train = pd.read_excel(filename)\r\n",
    "train.head(5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Classificacao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>quer fazer sua mulher feliz? come ela e da um ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@kimkataguiri que merda est√£o inventando, kim ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>algu√©m tem o link de spotify hackeado pra iphone?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@adr1nztte @charlidamelio mn pelo menos eu ain...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>favela venceu e meu iphone t√° vindo hjüòçüòò</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Classificacao\n",
       "0  quer fazer sua mulher feliz? come ela e da um ...              2\n",
       "1  @kimkataguiri que merda est√£o inventando, kim ...              0\n",
       "2  algu√©m tem o link de spotify hackeado pra iphone?              0\n",
       "3  @adr1nztte @charlidamelio mn pelo menos eu ain...              0\n",
       "4           favela venceu e meu iphone t√° vindo hjüòçüòò              1"
      ]
     },
     "metadata": {},
     "execution_count": 811
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\r\n",
    "test.head(5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classificacao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>meu patr√£o quer que eu pego o iphone 12 pr√≥ ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>comprei um m62 e vendi meu iphone me sinto com...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@omardodeboche @marcosrojerio2 @isabeledacpi e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>algu√©m que tenha o iphone 7 plus, sabe me dize...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>se algum amg gostasse de mim de vdd me dava um...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Classificacao\n",
       "0  meu patr√£o quer que eu pego o iphone 12 pr√≥ ma...              0\n",
       "1  comprei um m62 e vendi meu iphone me sinto com...              0\n",
       "2  @omardodeboche @marcosrojerio2 @isabeledacpi e...              0\n",
       "3  algu√©m que tenha o iphone 7 plus, sabe me dize...              0\n",
       "4  se algum amg gostasse de mim de vdd me dava um...              2"
      ]
     },
     "metadata": {},
     "execution_count": 812
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## Classificador autom√°tico de sentimento\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Fa√ßa aqui uma descri√ß√£o do seu produto e o que considerou como relevante ou n√£o relevante na classifica√ß√£o dos tweets.\r\n",
    "\r\n",
    "O produto escolhido foi o Iphone e consideramos tweets que demonstrassem a opini√£o popular referente ao iphone como sendo os tweets mais relevantes. Especificamente, consideramos a opini√£o popular quanto √† caracter√≠sticas do pr√≥prio iphone, como c√¢mera, bateria (elementos do hardware) e tamb√©m caracte√≠sticas mais subjetivas como o pre√ßo. Tweets que se distanciassem desses crit√©rios de relev√¢ncia foram avaliados como menos relevantes (evidentemente)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\r\n",
    "### Montando um Classificador Naive-Bayes\r\n",
    "\r\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador.\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "defini√ß√£o de fun√ß√µes de limpeza e usando natural language toolkit para remover stopwords, de modo a melhorar a precis√£o do classificador.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "source": [
    "nltk.download('stopwords') #remover stopwords\r\n",
    "s_words = nltk.corpus.stopwords.words('portuguese')\r\n",
    "s_list = [\"de\", \"√©\", \"√°\", \"√†\", \"ao\", \"a\", \"o\", \"√©\", \"rt\", '\"', \"‚Äú\", \"'\", \",\", \"(\", \")\", \"$\", \"%\", \"*\", \"&\", \"+\", \"=\"] #implementar stemming, palavras com mesmo stem s√£o tratadas como mesma palavra\r\n",
    "s_words.extend(s_list)  #remover palavras que se iniciam com @\r\n",
    "\r\n",
    "def cleanup(lista):\r\n",
    "        #Fun√ß√£o de limpeza que remove caracteres nao desejados e palavras nao desejados de strings de uma lista de strings\r\n",
    "    lista_limpa = []\r\n",
    "    for string in lista:\r\n",
    "        punctuation = '[!-.:?;]'\r\n",
    "        pattern = re.compile(punctuation)   #remover pontua√ß√£o\r\n",
    "        text_subbed = re.sub(pattern, '', string)\r\n",
    "        text_subbed.lower()\r\n",
    "        palavras = text_subbed.split(\" \") #separando a string em palavras\r\n",
    "        for palavra in palavras:\r\n",
    "            if palavra in s_words:      \r\n",
    "                palavras.remove(palavra) #removendo as stopwords\r\n",
    "            palavra.replace(\"\\n\",\" \")\r\n",
    "        lista_limpa.append(\" \".join(palavras))   #transformando a lista resultante em string    \r\n",
    "\r\n",
    "    return lista_limpa\r\n",
    "\r\n",
    "\r\n",
    "    "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "limpando a lista de opiniao, lista n√£o opini√£o e lista de teste. Importante notar que fizemos 4 categorias no banco de dados, contudo, pela dificuldade de implementa√ß√£o de mais de duas categorias e pela falta de m√£o de obra, como dupla, julgamos que seria mais prudente trabalhar apenas com duas categorias, para isso estipulamos que o que haviamos marcado como 2 e 3 agora ser√° 1 e o que foi marcado como 0 e 1 √© 0."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "source": [
    "\r\n",
    "opiniao = train.loc[(train[\"Classificacao\"] == 3) | (train[\"Classificacao\"] == 2),:] #reorganizando as categorias\r\n",
    "nao_opiniao = train.loc[(train[\"Classificacao\"] == 0) | (train[\"Classificacao\"] == 1),:]\r\n",
    "\r\n",
    "\r\n",
    "texto_opiniao_limpo = cleanup(opiniao[\"Treinamento\"].to_list()) #aplicando fun√ß√£o de limpeza\r\n",
    "texto_nao_opiniao_limpo = cleanup(nao_opiniao[\"Treinamento\"].to_list())\r\n",
    "\r\n",
    "\r\n",
    "palavras_opiniao = \" \".join(texto_opiniao_limpo).split(\" \")  #transformando listas de tweets limpos em listas de palavras contendo todas as palavras dos tweets\r\n",
    "palavras_nao_opiniao = \" \".join(texto_nao_opiniao_limpo).split(\" \") \r\n",
    "\r\n",
    "palavras_opiniao = [w for w in palavras_opiniao if w not in s_words] \r\n",
    "palavras_nao_opiniao = [w for w in palavras_nao_opiniao if w not in s_words]\r\n",
    "\r\n",
    "teste = []\r\n",
    "\r\n",
    "for tweet in test[\"Teste\"]:\r\n",
    "    tweet = cleanup(tweet.split(\" \"))\r\n",
    "    palavras_tweet = tweet\r\n",
    "    palavras_tweet = [w for w in palavras_tweet if w not in s_words]\r\n",
    "    teste.append(\" \".join(palavras_tweet))    #limpando tweets da lista de testes\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "pegando listas relativas e absolutas"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "source": [
    "\r\n",
    "lista_palavras_absoluta_opiniao = pd.Series(palavras_opiniao).value_counts()  #contando frequ√™ncias absoluta e relativa, respectivamente, das palavras em tanto a categoria opini√£o quanto n√£o opini√£o.\r\n",
    "lista_palavras_relativa_opiniao = pd.Series(palavras_opiniao).value_counts(normalize=True)\r\n",
    "\r\n",
    "lista_palavras_absoluta_nao_opiniao = pd.Series(palavras_nao_opiniao).value_counts()\r\n",
    "lista_palavras_relativa_nao_opiniao = pd.Series(palavras_nao_opiniao).value_counts(normalize=True)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Definindo os priors.\r\n",
    "Priors s√£o probabilidades √† priori (como o nome j√° implica). Esses coeficientes s√£o obtidos supondo-se que a soma das palavras das listas das categorias seja igual √† todo o vocabul√°rio portugu√™s e, portanto, podemos dividir o tamanho da lista de frequ√™ncias de palavras para cada categoria pelo n√∫mero de palavras no total e desse modo obtemos o prior de cada categoria. Vale notar que o tamanho da lista de frequ√™ncias de cada categoria representa o n√∫mero de palavras diferentes dessa categoria e que a lista de frequ√™ncia em quest√£o √© obtida por meio da fun√ß√£o value counts."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "source": [
    "\r\n",
    "total = len(lista_palavras_absoluta_opiniao)+len(lista_palavras_absoluta_nao_opiniao)\r\n",
    "prior_op = len(lista_palavras_absoluta_opiniao)/total\r\n",
    "prior_nop = len(lista_palavras_absoluta_nao_opiniao)/total  \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "VERIFICANDO O CLASSIFICADOR COM A BASE DE TESTES"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "source": [
    "\r\n",
    " \r\n",
    "def classify(lista_de_tweets,lista_palavras_absoluta_opiniao,lista_palavras_absoluta_nao_opiniao,prior_op,prior_nop): #funcao recebe uma lista de tweets, uma lista de frequencia de palavras opiniao, uma lista de frequencia de palavras nao opiniao, numero total de palavras e os priors\r\n",
    "    resultado = [] #lista resultado que vai guardar as classifica√ß√µes geradas pelo classificador\r\n",
    "    for tweet in lista_de_tweets: #loop que percorre todos os tweets da base de teste\r\n",
    "        prob_op =[]   #listas que v√£o guardar as probabilidades de cada palavra dentro do tweet para caso categoria opini√£o e caso categoria n√£o opini√£o\r\n",
    "        prob_nop =[]\r\n",
    "        for palavra in tweet:\r\n",
    "            prob_dado_opiniao = 1             #aplica√ß√£o da suaviza√ß√£o de laplace, que garante que para palavras que n√£o existem nos bancos de frequ√™ncia das categorias, n√£o haver√° multiplica√ß√£o por zero no produto das probabilidades de todas as probabilidades.\r\n",
    "            prob_dado_nao_opiniao = 1\r\n",
    "\r\n",
    "            prob_dado_opiniao *= 1/(len(lista_palavras_absoluta_opiniao)+total)\r\n",
    "            prob_dado_nao_opiniao *= 1/(len(lista_palavras_absoluta_nao_opiniao)+total)\r\n",
    "            if palavra in lista_palavras_absoluta_nao_opiniao:\r\n",
    "\r\n",
    "                prob_dado_nao_opiniao += (lista_palavras_absoluta_nao_opiniao[palavra])/(len(lista_palavras_absoluta_nao_opiniao)+total)\r\n",
    "\r\n",
    "            if palavra in lista_palavras_absoluta_opiniao:\r\n",
    "\r\n",
    "                prob_dado_opiniao += (lista_palavras_absoluta_opiniao[palavra])/(len(lista_palavras_absoluta_opiniao)+total)\r\n",
    "\r\n",
    "            prob_op.append(prob_dado_opiniao)\r\n",
    "            prob_nop.append(prob_dado_nao_opiniao)\r\n",
    "\r\n",
    "            prob_opiniao_dado_frase =  np.prod(prob_op)*prior_op  #calculo das probabilidades de opiniao dado tweet e nao opiniao dado tweet. Obtidos pelo produto das probabilidades de todas as palavras dado opiniao ou nao opiniao e, por fim, multiplica se o resultado desse grande produto pelos respectivos priors.\r\n",
    "            prob_nao_opiniao_dado_frase = np.prod(prob_nop)*prior_nop\r\n",
    "\r\n",
    "        if prob_opiniao_dado_frase > prob_nao_opiniao_dado_frase: #efetua-se a classifica√ß√£o avaliando qual das probabilidades dado frase √© maior.\r\n",
    "            resultado.append(1)\r\n",
    "        else:\r\n",
    "            resultado.append(0)\r\n",
    "    return resultado\r\n",
    "\r\n",
    "\r\n",
    "test[\"resultados\"] = classify(teste,lista_palavras_absoluta_opiniao,lista_palavras_absoluta_nao_opiniao,prior_op,prior_nop) #criando uma nova coluna no dataframe de testes, que guarda o resultado da classifica√ß√£o\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "source": [
    "serie_conv = []\r\n",
    "for i in test[\"Classificacao\"].to_list(): #transformando os 2 e 3 em 1 e os 0 e 1 em 0 na base de testes. Visto que apenas usamos um classificador de duas categorias.\r\n",
    "    if i == 2 or i == 3:\r\n",
    "        serie_conv.append(1)\r\n",
    "    if i == 0 or i == 1:\r\n",
    "        serie_conv.append(0)\r\n",
    "\r\n",
    "classific = pd.Series(serie_conv)\r\n",
    "pd.crosstab(classific,test[\"resultados\"])\r\n",
    "#"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>resultados</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>183</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "resultados    0   1\n",
       "row_0              \n",
       "0           183  36\n",
       "1            29   2"
      ]
     },
     "metadata": {},
     "execution_count": 818
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "source": [
    "pd.crosstab(classific,test['resultados'],normalize=\"index\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>resultados</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.835616</td>\n",
       "      <td>0.164384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.064516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "resultados         0         1\n",
       "row_0                         \n",
       "0           0.835616  0.164384\n",
       "1           0.935484  0.064516"
      ]
     },
     "metadata": {},
     "execution_count": 819
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Calculando os acertos. Comparando as classificacoes na base de teste e as classificacoes geradas pelo classificador. Calculando, acur√°cia, falsos positivos e negativos e verdadeiros positivos e negativos."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "source": [
    "lista_teste = [i for i in classific] \r\n",
    "lista_results = [i for i in test[\"resultados\"]]\r\n",
    "\r\n",
    "\r\n",
    "contador = 0\r\n",
    "verd_pos = 0\r\n",
    "verd_neg = 0\r\n",
    "falso_pos = 0\r\n",
    "falso_neg = 0\r\n",
    "\r\n",
    "for i in range(len(lista_teste)):\r\n",
    "    if lista_teste[i] == 1 and lista_results[i] == 1:\r\n",
    "        verd_pos += 1\r\n",
    "    if lista_teste[i] == 0 and  lista_results[i] == 0:\r\n",
    "        verd_neg += 1\r\n",
    "    if lista_teste[i] == 0 and lista_results[i] == 1:\r\n",
    "        falso_pos += 1\r\n",
    "    if lista_teste[i] ==  1 and lista_results[i] == 0:\r\n",
    "        falso_neg += 1\r\n",
    "    if lista_teste[i] == lista_results[i]:\r\n",
    "        contador += 1\r\n",
    "\r\n",
    "acertos = contador/len(lista_teste)\r\n",
    "acertos *= 100\r\n",
    "positivos = verd_pos + falso_pos\r\n",
    "negativos = verd_neg + falso_neg\r\n",
    "verd_pos /= positivos   #quantidade de verdadeiros positivos dividido pelo numero de positivos\r\n",
    "verd_neg /= negativos\r\n",
    "falso_pos /= positivos\r\n",
    "falso_neg /= negativos\r\n",
    "\r\n",
    "\r\n",
    "print(\"Acur√°cia: \"+str(acertos)+\"%\")\r\n",
    "print(\"Falsos positivos: \"+str(falso_pos*100)+\"%\")\r\n",
    "print(\"Falsos negativos: \"+str(falso_neg*100)+\"%\")\r\n",
    "print(\"verdadeiros positivos: \"+str(verd_pos*100)+\"%\")\r\n",
    "print(\"verdadeiros negativos: \"+str(verd_neg*100)+\"%\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Acur√°cia: 74.0%\n",
      "Falsos positivos: 94.73684210526315%\n",
      "Falsos negativos: 13.679245283018867%\n",
      "verdadeiros positivos: 5.263157894736842%\n",
      "verdadeiros negativos: 86.32075471698113%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "CONCLUSAO\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Criando um df com todos os tweets e classificacao"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "source": [
    "total_tweets = train[\"Treinamento\"].append(test[\"Teste\"])\r\n",
    "total_tweet_classificacao = train[\"Classificacao\"].append(test[\"Classificacao\"])\r\n",
    "total_df = pd.concat([total_tweets,total_tweet_classificacao],axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "source": [
    "lista_acuracia = [] #criando lista das acuracias de cada classificador\r\n",
    "for i in range(0,100):\r\n",
    "    df_random = total_df.sample(n=500)\r\n",
    "    df_train = df_random.head(300)\r\n",
    "    df_teste = df_random.tail(200)\r\n",
    "    opiniao = df_train.loc[(df_train[\"Classificacao\"] == 2) |(df_train[\"Classificacao\"] == 3),:]\r\n",
    "    nao_opiniao = df_train.loc[(df_train[\"Classificacao\"] == 0) |(df_train[\"Classificacao\"] == 1),:]\r\n",
    "\r\n",
    "    palavras_opiniao = []\r\n",
    "    palavras_nao_opiniao = []\r\n",
    "\r\n",
    "    lista_classific_teste = []\r\n",
    "\r\n",
    "    for i in df_teste[\"Classificacao\"]:\r\n",
    "        if i == 2 or i == 3:\r\n",
    "            lista_classific_teste.append(1)\r\n",
    "        if i == 0 or i == 1:\r\n",
    "            lista_classific_teste.append(0)\r\n",
    "\r\n",
    "\r\n",
    "    #limpando listas de treino\r\n",
    "    for tweet in opiniao[0]:\r\n",
    "        tweet = cleanup(tweet.split(\" \"))\r\n",
    "        palavras_tweet = tweet\r\n",
    "        palavras_tweet = [w for w in palavras_tweet if w not in s_words]\r\n",
    "        palavras_opiniao.extend(palavras_tweet)\r\n",
    "\r\n",
    "    for tweet in nao_opiniao[0]:\r\n",
    "        tweet = cleanup(tweet.split(\" \"))\r\n",
    "        palavras_tweet = tweet\r\n",
    "        palavras_tweet = [w for w in palavras_tweet if w not in s_words]\r\n",
    "        palavras_nao_opiniao.extend(palavras_tweet)\r\n",
    "\r\n",
    "    #limpando lista de teste\r\n",
    "    lista_teste = []\r\n",
    "\r\n",
    "    for tweet in df_teste[0]:\r\n",
    "        tweet = cleanup(tweet.split(\" \"))\r\n",
    "        palavras_tweet = tweet\r\n",
    "        palavras_tweet = [w for w in palavras_tweet if w not in s_words]\r\n",
    "        lista_teste.append(palavras_tweet)\r\n",
    "    l2 = []\r\n",
    "    for tweet in lista_teste:\r\n",
    "        l2.append(list(filter(None,tweet)))\r\n",
    "    lista_teste=l2\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "    palavras_opiniao = list(filter(None,palavras_opiniao))\r\n",
    "    palavras_nao_opiniao = list(filter(None,palavras_nao_opiniao))\r\n",
    "\r\n",
    "    lista_palavras_absoluta_opiniao = (pd.Series(palavras_opiniao)).value_counts()\r\n",
    "    lista_palavras_absoluta_nao_opiniao = (pd.Series(palavras_nao_opiniao)).value_counts()\r\n",
    "\r\n",
    "    total = len(lista_palavras_absoluta_opiniao) + len(lista_palavras_absoluta_nao_opiniao)\r\n",
    "\r\n",
    "    prior_op = len(lista_palavras_absoluta_opiniao)/total\r\n",
    "    prior_nop = len(lista_palavras_absoluta_nao_opiniao)/total\r\n",
    "\r\n",
    "    resultado = classify(lista_teste,lista_palavras_absoluta_opiniao,lista_palavras_absoluta_nao_opiniao,prior_op,prior_nop)\r\n",
    "\r\n",
    "    contador = 0\r\n",
    "    for i in range(len(lista_classific_teste)):\r\n",
    "        if lista_classific_teste[i] == resultado[i]:\r\n",
    "            contador += 1\r\n",
    "    acuracia = (contador/len(lista_classific_teste))*100\r\n",
    "    lista_acuracia.append(acuracia)\r\n",
    "\r\n",
    "soma = 0 \r\n",
    "for i in lista_acuracia:\r\n",
    "    soma += i\r\n",
    "acuracia_media = soma/100\r\n",
    "print(\"A acur√°cia m√©dia dos classificadores √©: \"+str(acuracia_media)+\"%\")\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "A acur√°cia m√©dia dos classificadores √©: 73.475%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\r\n",
    "## Aperfei√ßoamento:\r\n",
    "\r\n",
    "Trabalhos que conseguirem pelo menos conceito B v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\r\n",
    "\r\n",
    "* IMPLEMENTOU outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o contida nos tweets. Ex: stemming, lemmatization, stopwords\r\n",
    "* CORRIGIU separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis\r\n",
    "* CRIOU categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante. Pelo menos quatro categorias, com adi√ß√£o de mais tweets na base, conforme enunciado. (OBRIGAT√ìRIO PARA TRIOS, sem contar como item avan√ßado)\r\n",
    "* EXPLICOU porqu√™ n√£o pode usar o pr√≥prio classificador para gerar mais amostras de treinamento\r\n",
    "* PROP√îS diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\r\n",
    "* SUGERIU e EXPLICOU melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\r\n",
    "* FEZ o item 6. Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste descrito no enunciado do projeto (OBRIGAT√ìRIO para conceitos A ou A+)"
   ],
   "metadata": {},
   "attachments": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## Refer√™ncias"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "d98b4cf575a891b97ea43402398b6b9082f9e1cf0f07109cc211caf32ce43040"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}